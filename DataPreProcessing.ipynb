{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1918,"status":"ok","timestamp":1682996303377,"user":{"displayName":"Noah Himed","userId":"01275784072187732883"},"user_tz":240},"id":"hEXcY3UOmJl_","outputId":"204cd3bf-5711-496f-dc52-4aa452740dbc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')                                                   "]},{"cell_type":"code","source":["import os\n","import shutil\n","import math\n","import random\n","import numpy as np\n","\n","from glob import glob"],"metadata":{"id":"89LMEwHN7u-Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iwu0IfzSCWGr"},"outputs":[],"source":["def check_unique(lst):\n","    # use the unique function from numpy to find the unique elements in the list\n","    unique_elements, counts = np.unique(lst, return_counts=True)\n","    # return True if all elements in the list are unique (i.e., the counts are all 1)\n","    return all(counts == 1)\n","\n","def convert_files(labels_file_path, output_folder):\n","  written_ids = []\n","  def write_annotations(currentFrameID, perImageAnnotation):\n","    if len(perImageAnnotation) != 0:\n","      newImageGroundTruth = open(f\"{output_folder}/{currentFrameID}.txt\", \"w\")\n","      written_ids.append(currentFrameID)\n","      newImageGroundTruth.writelines(perImageAnnotation)\n","      newImageGroundTruth.close()\n","\n","  # Open ground truth file and set parameter to read (r)\n","  groundTruthFile = open(labels_file_path, 'r') \n","  Lines = groundTruthFile.readlines()\n","\n","  perImageAnnotation = ''\n","  currentFrameID = None\n","  imageWidth = 810\n","  imageHeight = 1080\n","  # line variable defined is each list of strings\n","  for line in Lines:\n","    bounding_box_parameters = line.strip().split(\",\")\n","    frameID, _, x, y, w, h =  bounding_box_parameters[:-3]\n","\n","    if currentFrameID is None:\n","      currentFrameID = frameID\n","    elif frameID != currentFrameID:\n","      write_annotations(currentFrameID, perImageAnnotation)\n","      perImageAnnotation = ''\n","      currentFrameID = frameID\n","  \n","    x = int(x)\n","    y = int(y)\n","    w = int(w)\n","    h = int(h)\n","    # convert from top left corner to center of image for bounding box\n","    # Normalize between 0 and 1 for YOLOv8 \n","    x += w/2\n","    y += h/2\n","    y = round(y/imageHeight, 2)\n","    h = round(h/imageHeight, 2)\n","    x = round(x/imageWidth, 2)\n","    w = round(w/imageWidth, 2) \n","    # Denote each annotation as belonging the same class with the class ID 0,\n","    # because the dataset only contains pictures of lettuce.\n","    perImageAnnotation += f\"0 {x} {y} {w} {h}\\n\"\n","    \n","  write_annotations(currentFrameID, perImageAnnotation)\n","\n","\n","def organize_datasets(label_path, image_path, output_dataset_path,\n","                      starting_frame_id):\n","  def move_files(label_image_pairs, output_label_path,\n","                 output_image_path, current_id):\n","      if not os.path.exists(output_label_path):\n","        os.makedirs(output_label_path)\n","\n","      if not os.path.exists(output_image_path):\n","        os.makedirs(output_image_path)\n","\n","      for label_file, image_file in label_image_pairs:\n","        label_file_id = os.path.splitext(os.path.basename(label_file))[0]\n","        image_file_id = os.path.splitext(os.path.basename(image_file))[0]\n","        if int(label_file_id) != int(image_file_id):\n","          raise ValueError(\"Mismatch in ground truth and image file IDs\")\n","\n","        # Rename and move the ground truth and image files.\n","        output_label_file_name = os.path.join(output_label_path, f\"{current_id}.txt\")\n","        output_image_file_name = os.path.join(output_image_path, f\"{current_id}.png\")\n","        shutil.copy(label_file, output_label_file_name)\n","        shutil.copy(image_file, output_image_file_name)\n","\n","        current_id += 1\n","\n","      return current_id\n","\n","\n","  # Rename the files to unique ID numbers.\n","  label_files = glob(f\"{label_path}/*.txt\")\n","  image_files = glob(f\"{image_path}/*.png\")\n","  label_files = sorted(\n","      label_files, \n","      key=lambda f: int(os.path.splitext(os.path.basename(f))[0])\n","  )\n","  image_files = sorted(\n","      image_files, \n","      key=lambda f: int(os.path.splitext(os.path.basename(f))[0])\n","  )\n","  label_image_pairs = list(\n","      map(lambda label_f, image_f: (label_f, image_f),\n","          label_files, image_files)\n","  )\n","  dataset_size = len(label_image_pairs)\n","\n","  # Split the dataset into train and validation subsets.\n","  TRAIN_PORTION = 0.9\n","  train_subset_size = math.floor(dataset_size * TRAIN_PORTION)\n","  val_subset_size = dataset_size - train_subset_size\n","  val_subset = set(random.sample(label_image_pairs, val_subset_size))\n","  train_subset = set(label_image_pairs) - val_subset\n","  \n","  # Copy the files to the new dataset directory\n","  output_val_label_path = os.path.join(output_dataset_path, \"val\", \"labels\")\n","  output_val_image_path = os.path.join(output_dataset_path, \"val\", \"images\")\n","  current_id = move_files(val_subset, output_val_label_path,\n","                          output_val_image_path, starting_frame_id)\n","\n","  output_train_ground_truth_path = os.path.join(output_dataset_path, \"train\", \"labels\")\n","  output_train_image_path = os.path.join(output_dataset_path, \"train\", \"images\")\n","  current_id = move_files(train_subset, output_train_ground_truth_path,\n","                          output_train_image_path, current_id)\n","  \n","  return current_id\n"]},{"cell_type":"markdown","source":["Convert the LettuceMOT dataset to YOLO format.\n","\n"],"metadata":{"id":"JePz7HPTKla1"}},{"cell_type":"code","source":["DATASET_ROOT_DIR = \"/content/drive/MyDrive/BRAE_428_Colab/LettuceMOT\"\n","YOLO_DATASET_PATH = \"/content/drive/MyDrive/BRAE_428_Colab/YoloDataset_v2\"\n","data_subsets = glob(f\"{DATASET_ROOT_DIR}/*\")\n","\n","if os.path.exists(YOLO_DATASET_PATH):\n","  raise ValueError(\"Make a new dir to avoid overwriting dataset\")\n","else:\n","  os.makedirs(YOLO_DATASET_PATH)\n","\n","data_count = 0\n","all_ids = []\n","for subset_path in data_subsets:\n","  mot_label_file_path = os.path.join(subset_path, \"gt\", \"gt.txt\")\n","  output_label_folder = os.path.join(subset_path, \"yolo_gt\")\n","  \n","  if not os.path.exists(output_label_folder):\n","    print(f\"Converting file {mot_label_file_path} to {output_label_folder}...\")\n","    convert_files(mot_label_file_path, YOLO_DATASET_PATH)\n","\n","  image_path = os.path.join(subset_path, \"img\")\n","  print(f\"Moving files from {image_path} to {YOLO_DATASET_PATH}...\")\n","  data_count = organize_datasets(output_label_folder, image_path,\n","                                 YOLO_DATASET_PATH, data_count)\n"," \n","  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cBWgXXYd6ypS","executionInfo":{"status":"ok","timestamp":1682997824371,"user_tz":240,"elapsed":1495783,"user":{"displayName":"Noah Himed","userId":"01275784072187732883"}},"outputId":"61103bbd-3f7d-45c7-9ff6-f662db7eb821"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Moving files from /content/drive/MyDrive/BRAE_428_Colab/LettuceMOT/straight1/img to /content/drive/MyDrive/BRAE_428_Colab/YoloDataset_v2...\n","Moving files from /content/drive/MyDrive/BRAE_428_Colab/LettuceMOT/B&F2/img to /content/drive/MyDrive/BRAE_428_Colab/YoloDataset_v2...\n","Moving files from /content/drive/MyDrive/BRAE_428_Colab/LettuceMOT/B&F1/img to /content/drive/MyDrive/BRAE_428_Colab/YoloDataset_v2...\n","Moving files from /content/drive/MyDrive/BRAE_428_Colab/LettuceMOT/straight2/img to /content/drive/MyDrive/BRAE_428_Colab/YoloDataset_v2...\n","Moving files from /content/drive/MyDrive/BRAE_428_Colab/LettuceMOT/straight4/img to /content/drive/MyDrive/BRAE_428_Colab/YoloDataset_v2...\n","Moving files from /content/drive/MyDrive/BRAE_428_Colab/LettuceMOT/straight3/img to /content/drive/MyDrive/BRAE_428_Colab/YoloDataset_v2...\n"]}]},{"cell_type":"markdown","source":["Verify that the correstness of the genereted YOLO-format dataset."],"metadata":{"id":"89p6oc1Gq84G"}},{"cell_type":"code","source":["all_label_fs = []\n","all_image_fs = []\n","\n","# Check that the number of labels matches the number of images\n","# in each subset.\n","YOLO_DATASET_PATH = \"/content/drive/MyDrive/BRAE_428_Colab/YoloDataset\"\n","for data_subset in [\"train\", \"val\"]:\n","  label_path = os.path.join(YOLO_DATASET_PATH, data_subset, \"labels\")\n","  image_path = os.path.join(YOLO_DATASET_PATH, data_subset, \"images\")\n","  \n","  label_fs = glob(f\"{label_path}/*.txt\")\n","  image_fs = glob(f\"{image_path}/*.png\")\n","  if len(label_fs) == len(image_fs):\n","    print(f\"{data_subset} subset: ✅\")\n","  else:\n","    print(f\"{data_subset} subset: ❌\")\n","    print(f\"{len(label_fs)} labels, {len(image_fs)}\")\n","\n","  all_label_fs += label_fs\n","  all_image_fs += image_fs\n","\n","# Check that no file names are repeated.\n","all_label_fs = [os.path.basename(f) for f in all_label_fs]\n","all_image_fs = [os.path.basename(f) for f in all_image_fs]\n","if check_unique(all_label_fs):\n","  print(\"No label file names reapeated: ✅\")\n","else:\n","  print(\"Label file names repeated: ❌\")\n","\n","if check_unique(all_image_fs):\n","  print(\"No image file names repeated: ✅\")\n","else:\n","  print(\"Image file names repeated: ❌\")\n","\n","print(f\"Dataset size: {len(all_label_fs)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJ5cVEL8q8kA","executionInfo":{"status":"ok","timestamp":1682999790984,"user_tz":240,"elapsed":311,"user":{"displayName":"Noah Himed","userId":"01275784072187732883"}},"outputId":"5771aed5-8fec-4b36-e5ab-aebaf3ddfede"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train subset: ✅\n","val subset: ✅\n","No label file names reapeated: ✅\n","No image file names repeated: ✅\n","Dataset size: 3163\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}